{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8178923a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-02T11:25:59.369913Z",
     "iopub.status.busy": "2025-12-02T11:25:59.369684Z",
     "iopub.status.idle": "2025-12-02T11:26:07.857684Z",
     "shell.execute_reply": "2025-12-02T11:26:07.856838Z"
    },
    "papermill": {
     "duration": 8.49278,
     "end_time": "2025-12-02T11:26:07.859016",
     "exception": false,
     "start_time": "2025-12-02T11:25:59.366236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "import copy\n",
    "import kaggle_evaluation.default_inference_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2093308a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T11:26:07.864779Z",
     "iopub.status.busy": "2025-12-02T11:26:07.864075Z",
     "iopub.status.idle": "2025-12-02T11:26:08.065194Z",
     "shell.execute_reply": "2025-12-02T11:26:08.064246Z"
    },
    "papermill": {
     "duration": 0.205008,
     "end_time": "2025-12-02T11:26:08.066435",
     "exception": false,
     "start_time": "2025-12-02T11:26:07.861427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 98)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ date_id â”† D1  â”† D2  â”† D3  â”† â€¦ â”† V9   â”† forward_returns â”† risk_free_rate â”† market_forward_excess_ â”‚\n",
      "â”‚ ---     â”† --- â”† --- â”† --- â”†   â”† ---  â”† ---             â”† ---            â”† returns                â”‚\n",
      "â”‚ i64     â”† i64 â”† i64 â”† i64 â”†   â”† str  â”† f64             â”† f64            â”† ---                    â”‚\n",
      "â”‚         â”†     â”†     â”†     â”†   â”†      â”†                 â”†                â”† f64                    â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 0       â”† 0   â”† 0   â”† 0   â”† â€¦ â”† null â”† -0.002421       â”† 0.000301       â”† -0.003038              â”‚\n",
      "â”‚ 1       â”† 0   â”† 0   â”† 0   â”† â€¦ â”† null â”† -0.008495       â”† 0.000303       â”† -0.009114              â”‚\n",
      "â”‚ 2       â”† 0   â”† 0   â”† 0   â”† â€¦ â”† null â”† -0.009624       â”† 0.000301       â”† -0.010243              â”‚\n",
      "â”‚ 3       â”† 0   â”† 0   â”† 0   â”† â€¦ â”† null â”† 0.004662        â”† 0.000299       â”† 0.004046               â”‚\n",
      "â”‚ 4       â”† 0   â”† 0   â”† 0   â”† â€¦ â”† null â”† -0.011686       â”† 0.000299       â”† -0.012301              â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "# 1. Load Training Data\n",
    "train_path = \"/kaggle/input/hull-tactical-market-prediction/train.csv\"\n",
    "df_train = pl.read_csv(train_path)\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e947259a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T11:26:08.071999Z",
     "iopub.status.busy": "2025-12-02T11:26:08.071537Z",
     "iopub.status.idle": "2025-12-02T11:26:08.285992Z",
     "shell.execute_reply": "2025-12-02T11:26:08.285192Z"
    },
    "papermill": {
     "duration": 0.218688,
     "end_time": "2025-12-02T11:26:08.287410",
     "exception": false,
     "start_time": "2025-12-02T11:26:08.068722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf = df_train.to_pandas()\n",
    "\n",
    "# price proxy\n",
    "pdf[\"price_proxy\"] = (1 + pdf[\"forward_returns\"].shift(1).fillna(0)).cumprod()\n",
    "\n",
    "# 1. price momentum\n",
    "for w in [5, 21, 63]:\n",
    "    pdf[f\"ret_{w}d_mom\"] = pdf[\"forward_returns\"].shift(1).fillna(0).rolling(w).sum()\n",
    "\n",
    "# 2. Moving averages\n",
    "for w in [5, 21, 63]:\n",
    "    ma_col = f\"ma_{w}\"\n",
    "    pdf[ma_col] = pdf[\"price_proxy\"].rolling(w).mean()\n",
    "    pdf[f\"price_over_ma_{w}\"] = pdf[\"price_proxy\"] / pdf[ma_col]\n",
    "\n",
    "# 3. Rolling volatility\n",
    "for w in [21, 63]:\n",
    "    pdf[f\"vol_{w}d\"] = pdf[\"forward_returns\"].shift(1).fillna(0).rolling(w).std()\n",
    "\n",
    "# drawdown proxy (recent w days cum of returns)\n",
    "for w in [21, 63]:\n",
    "    roll_cum = pdf[\"forward_returns\"].shift(1).fillna(0).rolling(w).sum()\n",
    "    roll_max = roll_cum.rolling(w).max()\n",
    "    pdf[f\"dd_{w}d\"] = roll_cum - roll_max\n",
    "\n",
    "df_train = pl.from_pandas(pdf)\n",
    "\n",
    "def generate_features(pdf):\n",
    "    df = pdf.copy()\n",
    "    \n",
    "    # 1. Price Proxy\n",
    "    df[\"price_proxy\"] = (1 + df[\"returns\"]).cumprod()\n",
    "\n",
    "    # 2. Price Momentum\n",
    "    for w in [5, 21, 63]:\n",
    "        df[f\"ret_{w}d_mom\"] = df[\"returns\"].rolling(w).sum()\n",
    "\n",
    "    # 3. Moving Averages\n",
    "    for w in [5, 21, 63]:\n",
    "        ma_col = f\"ma_{w}\"\n",
    "        df[ma_col] = df[\"price_proxy\"].rolling(w).mean()\n",
    "        df[f\"price_over_ma_{w}\"] = df[\"price_proxy\"] / df[ma_col]\n",
    "\n",
    "    # 4. Rolling Volatility\n",
    "    for w in [21, 63]:\n",
    "        df[f\"vol_{w}d\"] = df[\"returns\"].rolling(w).std()\n",
    "\n",
    "    # 5. Drawdown Proxy\n",
    "    for w in [21, 63]:\n",
    "        roll_cum = df[\"returns\"].rolling(w).sum()\n",
    "        roll_max = roll_cum.rolling(w).max()\n",
    "        df[f\"dd_{w}d\"] = roll_cum - roll_max\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2a6dc5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T11:26:08.292769Z",
     "iopub.status.busy": "2025-12-02T11:26:08.292548Z",
     "iopub.status.idle": "2025-12-02T11:26:08.618024Z",
     "shell.execute_reply": "2025-12-02T11:26:08.617395Z"
    },
    "papermill": {
     "duration": 0.32968,
     "end_time": "2025-12-02T11:26:08.619361",
     "exception": false,
     "start_time": "2025-12-02T11:26:08.289681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Training Data (Assuming df_train is already loaded)\n",
    "pdf_train = df_train.to_pandas()\n",
    "pdf_train = pdf_train.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Remove Future Data Leakage\n",
    "# Since 'forward_returns' represents returns from T to T+1, it is unknown at time T.\n",
    "# Therefore, applying shift(1) converts it to returns from T-1 to T (past data).\n",
    "# Assign this to the 'returns' column to be used in the shared feature generation function.\n",
    "pdf_train[\"returns\"] = pdf_train[\"forward_returns\"].shift(1).fillna(0)\n",
    "\n",
    "# Generate features using the shared function\n",
    "pdf_train = generate_features(pdf_train)\n",
    "\n",
    "# Handle NaNs created by rolling windows\n",
    "pdf_train = pdf_train.fillna(0)\n",
    "\n",
    "# Convert back to Polars DataFrame (To maintain pipeline consistency)\n",
    "df_train = pl.from_pandas(pdf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffdc8399",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T11:26:08.625064Z",
     "iopub.status.busy": "2025-12-02T11:26:08.624581Z",
     "iopub.status.idle": "2025-12-02T11:26:08.713444Z",
     "shell.execute_reply": "2025-12-02T11:26:08.712613Z"
    },
    "papermill": {
     "duration": 0.09322,
     "end_time": "2025-12-02T11:26:08.714872",
     "exception": false,
     "start_time": "2025-12-02T11:26:08.621652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. Preprocessing\n",
    "# Exclude non-feature columns\n",
    "ignore_cols = ['date_id', 'forward_returns', 'market_forward_excess_returns', 'risk_free_rate', 'returns']\n",
    "feature_cols = [c for c in df_train.columns if c not in ignore_cols]\n",
    "target_col = 'market_forward_excess_returns'\n",
    "\n",
    "# Convert to Pandas for CatBoost\n",
    "X = df_train.select(feature_cols).to_pandas()\n",
    "y = df_train.select(target_col).to_pandas().values.ravel()\n",
    "\n",
    "# Convert any non-numeric objects to NaN.\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Fill NaN with mean value by using SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed_array = imputer.fit_transform(X)\n",
    "X = pd.DataFrame(X_imputed_array, columns=X.columns)\n",
    "\n",
    "# Prepare data for volatility initialization (Last 60 days of returns)\n",
    "train_returns = df_train.select('forward_returns').tail(60).to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68ea7a87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T11:26:08.720678Z",
     "iopub.status.busy": "2025-12-02T11:26:08.720015Z",
     "iopub.status.idle": "2025-12-02T11:27:51.691529Z",
     "shell.execute_reply": "2025-12-02T11:27:51.690589Z"
    },
    "papermill": {
     "duration": 102.975666,
     "end_time": "2025-12-02T11:27:51.692766",
     "exception": false,
     "start_time": "2025-12-02T11:26:08.717100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Time-Series Cross-Validation (Comparing Models)...\n",
      "--------------------------------------------------\n",
      "Testing Model: CatBoost\n",
      "    Fold 1 MSE: 0.000151\n",
      "    Fold 2 MSE: 0.000103\n",
      "    Fold 3 MSE: 0.000188\n",
      "    Fold 4 MSE: 0.000071\n",
      "    Fold 5 MSE: 0.000133\n",
      "  -> CatBoost Average CV MSE: 0.000129\n",
      "Testing Model: LightGBM\n",
      "    Fold 1 MSE: 0.000159\n",
      "    Fold 2 MSE: 0.000140\n",
      "    Fold 3 MSE: 0.000207\n",
      "    Fold 4 MSE: 0.000082\n",
      "    Fold 5 MSE: 0.000158\n",
      "  -> LightGBM Average CV MSE: 0.000149\n",
      "Testing Model: RandomForest\n",
      "    Fold 1 MSE: 0.000156\n",
      "    Fold 2 MSE: 0.000125\n",
      "    Fold 3 MSE: 0.000186\n",
      "    Fold 4 MSE: 0.000069\n",
      "    Fold 5 MSE: 0.000135\n",
      "  -> RandomForest Average CV MSE: 0.000134\n",
      "--------------------------------------------------\n",
      "ğŸ† Best Model: CatBoost (MSE: 0.000129)\n"
     ]
    }
   ],
   "source": [
    "# 3. Time-Series Cross-Validation (Validation ONLY)\n",
    "tscv = TimeSeriesSplit(n_splits=5) \n",
    "cv_scores = []\n",
    "\n",
    "# Define models to compare in a dictionary\n",
    "models_config = {\n",
    "    \"CatBoost\": CatBoostRegressor(\n",
    "        iterations=600, learning_rate=0.03, depth=6, \n",
    "        loss_function='RMSE', verbose=False, allow_writing_files=False, random_seed=42\n",
    "    ),\n",
    "    \"LightGBM\": LGBMRegressor(\n",
    "        n_estimators=600, learning_rate=0.03, max_depth=6, \n",
    "        verbosity=-1, random_state=42, n_jobs=-1\n",
    "    ),\n",
    "    \"RandomForest\": RandomForestRegressor(\n",
    "        n_estimators=200, max_depth=10, \n",
    "        random_state=42, n_jobs=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "results = {}      # Store CV scores for each model\n",
    "best_score = float('inf') # Initial value for finding minimum MSE\n",
    "best_model_name = \"\"\n",
    "best_model_instance = None\n",
    "\n",
    "print(\"Starting Time-Series Cross-Validation (Comparing Models)...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Loop through each model to perform CV\n",
    "for model_name, model_instance in models_config.items():\n",
    "    print(f\"Testing Model: {model_name}\")\n",
    "    cv_scores = []\n",
    "    \n",
    "    for fold, (train_index, val_index) in enumerate(tscv.split(X)):\n",
    "        X_train_cv, X_val_cv = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train_cv, y_val_cv = y[train_index], y[val_index]\n",
    "        \n",
    "        # Initialize model\n",
    "        if model_name == \"CatBoost\":\n",
    "             # CatBoost requires specific parameter handling\n",
    "             current_model = CatBoostRegressor(**model_instance.get_params())\n",
    "        else:\n",
    "             # Standard Scikit-Learn compatible models (RF, LGBM)\n",
    "             current_model = model_instance.__class__(**model_instance.get_params())\n",
    "\n",
    "        current_model.fit(X_train_cv, y_train_cv)\n",
    "        \n",
    "        preds = current_model.predict(X_val_cv)\n",
    "        mse = mean_squared_error(y_val_cv, preds)\n",
    "        cv_scores.append(mse)\n",
    "\n",
    "        print(f\"    Fold {fold+1} MSE: {mse:.6f}\")\n",
    "    \n",
    "    # Calculate average MSE\n",
    "    avg_mse = np.mean(cv_scores)\n",
    "    results[model_name] = avg_mse\n",
    "    print(f\"  -> {model_name} Average CV MSE: {avg_mse:.6f}\")\n",
    "    \n",
    "    # Update the best performing model (Lower MSE is better)\n",
    "    if avg_mse < best_score:\n",
    "        best_score = avg_mse\n",
    "        best_model_name = model_name\n",
    "        # Save the instance to retrain on full data later\n",
    "        best_model_instance = model_instance\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"ğŸ† Best Model: {best_model_name} (MSE: {best_score:.6f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55ad6d41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T11:27:51.699517Z",
     "iopub.status.busy": "2025-12-02T11:27:51.698914Z",
     "iopub.status.idle": "2025-12-02T11:27:59.120048Z",
     "shell.execute_reply": "2025-12-02T11:27:59.119272Z"
    },
    "papermill": {
     "duration": 7.425574,
     "end_time": "2025-12-02T11:27:59.121220",
     "exception": false,
     "start_time": "2025-12-02T11:27:51.695646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Final Model (CatBoost) on ALL data...\n",
      "Final model training completed.\n"
     ]
    }
   ],
   "source": [
    "# 4. Final Model Training\n",
    "# Retrain the BEST model on the FULL dataset to capture the most recent market trends\n",
    "print(f\"Training Final Model ({best_model_name}) on ALL data...\")\n",
    "\n",
    "if best_model_name == \"CatBoost\":\n",
    "    final_model = CatBoostRegressor(**best_model_instance.get_params())\n",
    "else:\n",
    "    final_model = best_model_instance.__class__(**best_model_instance.get_params())\n",
    "\n",
    "final_model.fit(X, y)\n",
    "print(\"Final model training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb41bd9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T11:27:59.127976Z",
     "iopub.status.busy": "2025-12-02T11:27:59.127582Z",
     "iopub.status.idle": "2025-12-02T11:27:59.134104Z",
     "shell.execute_reply": "2025-12-02T11:27:59.133414Z"
    },
    "papermill": {
     "duration": 0.01107,
     "end_time": "2025-12-02T11:27:59.135228",
     "exception": false,
     "start_time": "2025-12-02T11:27:59.124158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5. Volatility Management Class\n",
    "class VolatilityController:\n",
    "    def __init__(self, window_size=60, target_ratio=1.15, initial_returns=None):\n",
    "        self.window_size = window_size\n",
    "        self.target_ratio = target_ratio\n",
    "        self.history = []\n",
    "        \n",
    "        # Initialize buffer with the end of training data\n",
    "        if initial_returns is not None:\n",
    "            for ret in initial_returns:\n",
    "                self.history.append({'market_ret': ret, 'weight': 1.0})\n",
    "\n",
    "    def calculate_safe_weight(self, raw_weight, current_lagged_return, last_weight):\n",
    "        # Update history with realized return from the previous step\n",
    "        if current_lagged_return is not None:\n",
    "             self.history.append({'market_ret': current_lagged_return, 'weight': last_weight})\n",
    "        \n",
    "        # Maintain window size\n",
    "        if len(self.history) > self.window_size:\n",
    "            self.history.pop(0)\n",
    "            \n",
    "        # Warm-up check\n",
    "        if len(self.history) < 10:\n",
    "            return raw_weight\n",
    "            \n",
    "        # Calculate Volatility Ratio\n",
    "        market_rets = np.array([x['market_ret'] for x in self.history])\n",
    "        weights = np.array([x['weight'] for x in self.history])\n",
    "        strategy_rets = weights * market_rets\n",
    "        \n",
    "        vol_bench = np.std(market_rets)\n",
    "        vol_strat = np.std(strategy_rets)\n",
    "        \n",
    "        if vol_bench < 1e-7: \n",
    "            return raw_weight\n",
    "\n",
    "        current_ratio = vol_strat / vol_bench\n",
    "        \n",
    "        # Apply scaling if ratio exceeds target (1.15 to be safe for 1.20 limit)\n",
    "        scaling_factor = 1.0\n",
    "        if current_ratio > self.target_ratio:\n",
    "            scaling_factor = self.target_ratio / current_ratio\n",
    "            \n",
    "        return raw_weight * scaling_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1699d935",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T11:27:59.141977Z",
     "iopub.status.busy": "2025-12-02T11:27:59.141542Z",
     "iopub.status.idle": "2025-12-02T11:27:59.454552Z",
     "shell.execute_reply": "2025-12-02T11:27:59.453681Z"
    },
    "papermill": {
     "duration": 0.317791,
     "end_time": "2025-12-02T11:27:59.455716",
     "exception": false,
     "start_time": "2025-12-02T11:27:59.137925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current test : 8980\n",
      "pred_excess_return : 0.010577032719402874\n",
      "raw_weight : 1.05283591490294\n",
      "final_weight : 1.05283591490294\n",
      "\n",
      "current test : 8981\n",
      "pred_excess_return : 0.007735800350770799\n",
      "raw_weight : 1.0386597245205733\n",
      "final_weight : 1.0386597245205733\n",
      "\n",
      "current test : 8982\n",
      "pred_excess_return : 0.012769460007115332\n",
      "raw_weight : 1.0637606839029314\n",
      "final_weight : 1.0637606839029314\n",
      "\n",
      "current test : 8983\n",
      "pred_excess_return : 0.013328664322287232\n",
      "raw_weight : 1.0665448348600668\n",
      "final_weight : 1.0665448348600668\n",
      "\n",
      "current test : 8984\n",
      "pred_excess_return : 0.009621347743269334\n",
      "raw_weight : 1.0480696625642065\n",
      "final_weight : 1.0480696625642065\n",
      "\n",
      "current test : 8985\n",
      "pred_excess_return : 0.009443515561994438\n",
      "raw_weight : 1.0471825185510155\n",
      "final_weight : 1.0471825185510155\n",
      "\n",
      "current test : 8986\n",
      "pred_excess_return : 0.00943034887316593\n",
      "raw_weight : 1.04711683146069\n",
      "final_weight : 1.04711683146069\n",
      "\n",
      "current test : 8987\n",
      "pred_excess_return : 0.008516439137097726\n",
      "raw_weight : 1.0425564770440459\n",
      "final_weight : 1.0425564770440459\n",
      "\n",
      "current test : 8988\n",
      "pred_excess_return : 0.0071895113130112445\n",
      "raw_weight : 1.035932080432205\n",
      "final_weight : 1.035932080432205\n",
      "\n",
      "current test : 8989\n",
      "pred_excess_return : 0.006619959002148428\n",
      "raw_weight : 1.033087712300078\n",
      "final_weight : 1.033087712300078\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Controller\n",
    "vol_manager = VolatilityController(window_size=60, target_ratio=1.15, initial_returns=train_returns)\n",
    "history_returns = []\n",
    "last_submitted_weight = 1.0 \n",
    "\n",
    "# 6. Inference Function\n",
    "def predict(test: pl.DataFrame) -> float:\n",
    "    global last_submitted_weight, history_returns\n",
    "    try:\n",
    "        new_ret = test.select(\"lagged_forward_returns\").item(0, 0)\n",
    "        \n",
    "        # ì²« ë²ˆì§¸ ë°ì´í„°ê°€ nullì¼ ê²½ìš° ì²˜ë¦¬\n",
    "        if new_ret is None: \n",
    "            new_ret = 0.0\n",
    "            \n",
    "        history_returns.append(new_ret)\n",
    "        \n",
    "        # # ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•´ í•„ìš”í•œ ìµœëŒ€ ìœˆë„ìš°(63ì¼) + ì—¬ìœ ë¶„(e.g., 100ê°œ)ë§Œ ìœ ì§€\n",
    "        # if len(history_returns) > 100:\n",
    "        #     history_returns.pop(0)\n",
    "            \n",
    "        # Real-time Feature Engineering\n",
    "        hist_df = pd.DataFrame({\"returns\": history_returns})\n",
    "        \n",
    "        # ê³µí†µ í•¨ìˆ˜ í˜¸ì¶œ (Step 3ì™€ ì™„ë²½íˆ ë™ì¼í•œ ë¡œì§ ì ìš©)\n",
    "        hist_df_feat = generate_features(hist_df)\n",
    "        \n",
    "        # Extract the last row (Current Timestep T) and reset index for concatenation\n",
    "        current_engineered_feat = hist_df_feat.iloc[[-1]].copy().reset_index(drop=True)\n",
    "        \n",
    "        # Combine Raw Features & Engineered Features\n",
    "        # Convert raw test data (M*, P*, etc.) to Pandas\n",
    "        test_pd = test.to_pandas()\n",
    "        \n",
    "        # Concatenate Raw Features + Engineered Features\n",
    "        X_test_full = pd.concat([test_pd, current_engineered_feat], axis=1)\n",
    "        X_test = X_test_full.reindex(columns=feature_cols, fill_value=0)\n",
    "        \n",
    "        # Prediction using the FINAL MODEL (Trained on all data)\n",
    "        pred_excess_return = final_model.predict(X_test)[0]\n",
    "        \n",
    "        # Sigmoid Betting Strategy (Output 0 ~ 2)\n",
    "        # Using a fixed scale factor (heuristic)\n",
    "        scale_factor = 10.0\n",
    "        if pred_excess_return < 0:\n",
    "            # Negative: Aggressive scaling\n",
    "            # Even a small negative prediction will drop weight significantly\n",
    "            scale_factor *= 5  # 5x more sensitive to downside\n",
    "        \n",
    "        sigmoid_value = 1 / (1 + np.exp(-pred_excess_return * scale_factor))\n",
    "        raw_weight = 2.0 * sigmoid_value\n",
    "        \n",
    "        # Volatility Control\n",
    "        final_weight = vol_manager.calculate_safe_weight(raw_weight, new_ret, last_submitted_weight)\n",
    "        \n",
    "        # Hard clip to ensure valid submission\n",
    "        final_weight = max(0.0, min(2.0, final_weight))\n",
    "        \n",
    "        # Update state for next iteration\n",
    "        last_submitted_weight = final_weight\n",
    "\n",
    "        # Print test information\n",
    "        print(f\"current test : {test.select('date_id').item(0, 0)}\")\n",
    "        print(f\"pred_excess_return : {pred_excess_return}\")\n",
    "        print(f\"raw_weight : {raw_weight}\")\n",
    "        print(f\"final_weight : {final_weight}\")\n",
    "        print()\n",
    "        \n",
    "        return float(final_weight)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        # Safety fallback\n",
    "        return 0.0\n",
    "\n",
    "# Start Inference Server\n",
    "inference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(('/kaggle/input/hull-tactical-market-prediction/',))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14348714,
     "isSourceIdPinned": false,
     "sourceId": 111543,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 124.373879,
   "end_time": "2025-12-02T11:28:00.277250",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-02T11:25:55.903371",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
